{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "338da719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oliver/opt/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/oliver/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 6): Library not loaded: @rpath/libpng16.16.dylib\n",
      "  Referenced from: /Users/oliver/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: Incompatible library version: image.so requires version 56.0.0 or later, but libpng16.16.dylib provides version 54.0.0'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports Here\n",
    "\"\"\"\n",
    "\"\"\"numpy and torch\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\"\"\"PIL\"\"\"\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"torchvision and utils\"\"\"\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\"\"\"os\"\"\"\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65011ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLoading data from local file\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading data from local file\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "206e485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Assumes images have pixel values in range [0,255]\"\"\"\n",
    "def getImages(trainDIRs, testDIRS):\n",
    "    \"\"\"Get image to tensor\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.PILToTensor()\n",
    "    ])\n",
    "    \"\"\"Loading data into arrays\"\"\"\n",
    "    xtrain, xtrain, xtest, ytest = [], [], [], []\n",
    "    \"\"\"training data\"\"\"\n",
    "    size = [0, 0]\n",
    "    for i, DIR in enumerate(trainDIRs):\n",
    "        px = []\n",
    "        j = 0\n",
    "        for filename in sorted(os.listdir(DIR)):\n",
    "            f = os.path.join(DIR, filename)\n",
    "            img = Image.open(f)\n",
    "            tensor = transform(img).float()\n",
    "            tensor.require_grad = True\n",
    "            px.append(tensor/255)\n",
    "            j  = (j+1) % 20\n",
    "            if j == 0:\n",
    "                xtrain.append(torch.stack(px))\n",
    "                px = []\n",
    "                size[i] += 1\n",
    "    xtrain = torch.stack(xtrain)\n",
    "    ytrain = torch.from_numpy(np.concatenate((np.ones(size[0]), np.zeros(size[1])), axis=0))\n",
    "        \n",
    "    \"\"\"testing data\"\"\"\n",
    "    size = [0, 0]\n",
    "    for i, DIR in enumerate(testDIRs):\n",
    "        px = []\n",
    "        j = 0\n",
    "        for filename in sorted(os.listdir(DIR)):\n",
    "            f = os.path.join(DIR, filename)\n",
    "            img = Image.open(f)\n",
    "            tensor = transform(img).float()\n",
    "            tensor.require_grad = True\n",
    "            px.append(tensor/255)\n",
    "            j = (j+1) % 20\n",
    "            if j == 0:\n",
    "                xtest.append(torch.stack(px))\n",
    "                px = []\n",
    "                size[i] += 1\n",
    "    xtest = torch.stack(xtest)\n",
    "    ytest = torch.from_numpy(np.concatenate((np.ones(size[0]), np.zeros(size[1])), axis=0))\n",
    "    return xtrain, ytrain, xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0897522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDataloader\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dataloader\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c80732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetWrapper(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X, self.y = X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X[idx]\n",
    "        else:\n",
    "            return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea41eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDIRs = ['../../../AD_NC/train/AD/', '../../../AD_NC/train/NC']\n",
    "testDIRs = ['../../../AD_NC/test/AD/', '../../../AD_NC/test/NC']\n",
    "xtrain, ytrain, xtest, ytest = getImages(trainDIRs, testDIRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a161d76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1076, 20, 1, 240, 256])\n",
      "torch.Size([450, 20, 1, 240, 256])\n",
      "torch.Size([450])\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "848190bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 192, 96])\n",
      "0.2741\n"
     ]
    }
   ],
   "source": [
    "class ConvLayer2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #pool\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        #first layer\n",
    "        self.conv11_x = nn.Conv2d(20, 48, kernel_size=(11,11), stride=(4,4), padding=(0,0))\n",
    "        self.conv11_y = nn.Conv2d(240, 48, kernel_size=(11,3), stride=(4,1), padding=(0,0))\n",
    "        self.conv11_z = nn.Conv2d(256, 48, kernel_size=(3,11), stride=(1,4), padding=(0,0))\n",
    "        #second layer\n",
    "        self.conv5_x = nn.Conv2d(48, 192, kernel_size=(5,5), stride=(2,2), padding=(0,0))\n",
    "        self.conv5_y = nn.Conv2d(48, 192, kernel_size=(5,3), stride=(2,1), padding=(0,0))\n",
    "        self.conv5_z = nn.Conv2d(48, 192, kernel_size=(3,5), stride=(1,2), padding=(0,0))\n",
    "        #projection\n",
    "        self.l_x = nn.Linear(30, 32)\n",
    "        self.l_y = nn.Linear(12, 32)\n",
    "        self.l_z = nn.Linear(10, 32)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        #input N, C, L, W, H\n",
    "        #first layer\n",
    "        x_x = self.relu(self.pool(self.conv11_x(imgs.flatten(1,2))))\n",
    "        x_y = self.relu(self.pool(self.conv11_y(imgs.permute(0,1,3,4,2).flatten(1,2))))\n",
    "        x_z = self.relu(self.pool(self.conv11_z(imgs.permute(0,1,4,2,3).flatten(1,2))))\n",
    "        #second layer\n",
    "        x_x = self.relu(self.pool(self.conv5_x(x_x)))\n",
    "        x_y = self.relu(self.pool(self.conv5_y(x_y)))\n",
    "        x_z = self.relu(self.pool(self.conv5_z(x_z)))\n",
    "        #projection\n",
    "        x_x = self.l_x(x_x.flatten(2,3))\n",
    "        x_y = self.l_y(x_y.flatten(2,3))\n",
    "        x_z = self.l_z(x_z.flatten(2,3))\n",
    "        return torch.cat([x_x, x_y, x_z], dim=2)\n",
    "import time\n",
    "start = time.time()\n",
    "conv=ConvLayer2()\n",
    "print(conv(xtrain[0:16,:].permute(0,2,1,3,4)).shape)\n",
    "end = time.time()\n",
    "print(round(end-start, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f295ee82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.004753589630127\n"
     ]
    }
   ],
   "source": [
    "conv_11 = nn.Conv2d(20, 64, kernel_size=(11,11), stride=(4,4), padding=(0,0))\n",
    "import time\n",
    "total = 0\n",
    "for i in range(10):\n",
    "    start=time.time()\n",
    "    x = conv_11(xtrain[0:16, :].permute(0,2,1,3,4).flatten(1,2))\n",
    "    end = time.time()\n",
    "    total += end-start\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e39d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1076, 256, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv11 = nn.Conv3d(1, 64, kernel_size=(3,11,11), stride=(1,4,4), padding=(1,0,0))\n",
    "        self.firstpool = nn.MaxPool3d(kernel_size=3, stride=2)\n",
    "        self.conv5 = nn.Conv3d(64, 256, kernel_size=(3,5,5), stride=(1,2,2), padding=(1,0,0))\n",
    "        self.secondpool = nn.MaxPool3d(kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        x = self.conv11(imgs)\n",
    "        x = self.firstpool(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.secondpool(x)\n",
    "        return x\n",
    "    \n",
    "conv = ConvLayer()\n",
    "x = conv(xtrain.permute(0,2,1,3,4))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a02e05bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainloader(batchsize=16):\n",
    "    return DataLoader(DatasetWrapper(xtrain, ytrain), batchsize=batchsize, shuffle=True)\n",
    "\n",
    "def testloader():\n",
    "    return DataLoader(DatasetWrapper(xtest, ytest), batchsize=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18d6ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainshape():\n",
    "    return xtrain.shape\n",
    "\n",
    "def testshape():\n",
    "    return xtest.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
