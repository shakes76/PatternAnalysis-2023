# Visual Transformer (ViT) for classifying Alzheimer's Disease

## OVERVIEW:
This project is dedicated to creating a machine learning model for the classification of Alzheimer's disease (AD) and normal brain scans, employing advanced Visual or Perceiver Transformer models. The primary objective is to achieve a minimum accuracy of 0.8 on the test dataset
n 2020, the groundbreaking paper titled "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale" demonstrated that traditional Convolutional Neural Networks could be surpassed by Vision Transformers. These Vision Transformers proved capable of delivering outstanding results when compared to state-of-the-art convolutional networks, all while demanding fewer computational resources for training.The adoption of Vision Transformers in this project is driven by the potential to harness their efficiency and accuracy in medical image classification, ultimately contributing to the advancement of Alzheimer's disease diagnosis and enhancing the healthcare landscape.



![visual transformer](https://github.com/saakshigupta2002/PatternAnalysis-2023/assets/62831255/579168d1-8dbe-4177-a549-52b8a930319c)

 
![visual transformer 2](https://github.com/saakshigupta2002/PatternAnalysis-2023/assets/62831255/65c75279-c984-46bc-8ead-3a93d7b80c49)
