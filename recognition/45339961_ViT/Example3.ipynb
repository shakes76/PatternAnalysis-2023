{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x279ed0a88f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "transform = ToTensor()\n",
    "\n",
    "train_set = MNIST(root='D:/MNIST/', train=True, download=True, transform=transform)\n",
    "test_set = MNIST(root='D:/MNIST/', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify(images, n_patches):\n",
    "    n, c, h, w = images.shape\n",
    "\n",
    "    assert h == w, \"Patchify method is implemented for square images only\"\n",
    "\n",
    "    patches = torch.zeros(n, n_patches ** 2, h * w * c // n_patches ** 2)\n",
    "    patch_size = h // n_patches\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        for i in range(n_patches):\n",
    "            for j in range(n_patches):\n",
    "                patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]\n",
    "                patches[idx, i * n_patches + j] = patch.flatten()\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embeddings(sequence_length, d):\n",
    "    result = torch.ones(sequence_length, d)\n",
    "    for i in range(sequence_length):\n",
    "        for j in range(d):\n",
    "            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMSA(nn.Module):\n",
    "    def __init__(self, d, n_heads=2):\n",
    "        super(MyMSA, self).__init__()\n",
    "        self.d = d\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        assert d % n_heads == 0, f\"Can't divide dimension {d} into {n_heads} heads\"\n",
    "\n",
    "        d_head = int(d / n_heads)\n",
    "        self.q_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.k_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.v_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
    "        self.d_head = d_head\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        # Sequences has shape (N, seq_length, token_dim)\n",
    "        # We go into shape    (N, seq_length, n_heads, token_dim / n_heads)\n",
    "        # And come back to    (N, seq_length, item_dim)  (through concatenation)\n",
    "        result = []\n",
    "        for sequence in sequences:\n",
    "            seq_result = []\n",
    "            for head in range(self.n_heads):\n",
    "                q_mapping = self.q_mappings[head]\n",
    "                k_mapping = self.k_mappings[head]\n",
    "                v_mapping = self.v_mappings[head]\n",
    "\n",
    "                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]\n",
    "                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n",
    "\n",
    "                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n",
    "                seq_result.append(attention @ v)\n",
    "            result.append(torch.hstack(seq_result))\n",
    "        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyViTBlock(nn.Module):\n",
    "    def __init__(self, hidden_d, n_heads, mlp_ratio=4):\n",
    "        super(MyViTBlock, self).__init__()\n",
    "        self.hidden_d = hidden_d\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(hidden_d)\n",
    "        self.mhsa = MyMSA(hidden_d, n_heads)\n",
    "        self.norm2 = nn.LayerNorm(hidden_d)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_d, mlp_ratio * hidden_d),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_ratio * hidden_d, hidden_d)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.mhsa(self.norm1(x))\n",
    "        out = out + self.mlp(self.norm2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyViT(nn.Module):\n",
    "    def __init__(self, chw, n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10):\n",
    "        # Super constructor\n",
    "        super(MyViT, self).__init__()\n",
    "        \n",
    "        # Attributes\n",
    "        self.chw = chw # ( C , H , W )\n",
    "        self.n_patches = n_patches\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_heads = n_heads\n",
    "        self.hidden_d = hidden_d\n",
    "        \n",
    "        # Input and patches sizes\n",
    "        assert chw[1] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        assert chw[2] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "        self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)\n",
    "\n",
    "        # 1) Linear mapper\n",
    "        self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])\n",
    "        self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)\n",
    "        \n",
    "        # 2) Learnable classification token\n",
    "        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))\n",
    "        \n",
    "        # 3) Positional embedding\n",
    "        self.register_buffer('positional_embeddings', get_positional_embeddings(n_patches ** 2 + 1, hidden_d), persistent=False)\n",
    "        \n",
    "        # 4) Transformer encoder blocks\n",
    "        self.blocks = nn.ModuleList([MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])\n",
    "        \n",
    "        # 5) Classification MLPk\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.hidden_d, out_d),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, images):\n",
    "        # Dividing images into patches\n",
    "        n, c, h, w = images.shape\n",
    "        patches = patchify(images, self.n_patches).to(self.positional_embeddings.device)\n",
    "        \n",
    "        # Running linear layer tokenization\n",
    "        # Map the vector corresponding to each patch to the hidden size dimension\n",
    "        tokens = self.linear_mapper(patches)\n",
    "        \n",
    "        # Adding classification token to the tokens\n",
    "        tokens = torch.cat((self.class_token.expand(n, 1, -1), tokens), dim=1)\n",
    "        \n",
    "        # Adding positional embedding\n",
    "        out = tokens + self.positional_embeddings.repeat(n, 1, 1)\n",
    "        \n",
    "        # Transformer Blocks\n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "            \n",
    "        # Getting the classification token only\n",
    "        out = out[:, 0]\n",
    "        \n",
    "        return self.mlp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda (NVIDIA GeForce RTX 3060 Laptop GPU)\n"
     ]
    }
   ],
   "source": [
    "# Defining model and training options\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "model = MyViT((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10).to(device)\n",
    "N_EPOCHS = 5\n",
    "LR = 0.005\n",
    "optimizer = Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 1/5 [08:16<33:07, 496.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 loss: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 2/5 [16:23<24:32, 490.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 loss: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 3/5 [24:32<16:19, 489.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 loss: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 4/5 [32:35<08:07, 487.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 loss: 1.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5/5 [40:40<00:00, 488.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 loss: 1.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in trange(N_EPOCHS, desc=\"Training\"):\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        train_loss += loss.detach().cpu().item() / len(train_loader)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 79/79 [00:58<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.71\n",
      "Test accuracy: 75.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test loop\n",
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    test_loss = 0.0\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        test_loss += loss.detach().cpu().item() / len(test_loader)\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "    print(f\"Test loss: {test_loss:.2f}\")\n",
    "    print(f\"Test accuracy: {correct / total * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
