{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPllL08zMM9Uj7rwxn2GwU8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "C1oCBoLsedJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class BrainSlicesDataset(Dataset):\n",
        "    def __init__(self, image_slices):\n",
        "        self.image_slices = image_slices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_slices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image_slices[idx]\n",
        "\n",
        "        # Ensure the image has a channel dimension\n",
        "        if len(image.shape) == 2:  # If the image is of shape [H, W]\n",
        "            image = torch.unsqueeze(image, 0)  # Convert it to [1, H, W]\n",
        "\n",
        "        return image\n",
        "\n",
        "def get_image_slices():\n",
        "    zip_path = \"/content/drive/MyDrive/Colab_Notebooks_Course/image_process/A3/testgans/GAN_Dataset.zip\"\n",
        "    extraction_path = \"/content/GAN_Dataset\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extraction_path)\n",
        "\n",
        "    parent_dir = \"/content/GAN_Dataset\"\n",
        "    train_path = os.path.join(parent_dir, \"keras_png_slices_train\")\n",
        "    test_path = os.path.join(parent_dir, \"keras_png_slices_test\")\n",
        "    val_path = os.path.join(parent_dir, \"keras_png_slices_validate\")\n",
        "\n",
        "    def load_images_from_folder(folder_path):\n",
        "            images = []\n",
        "            for filename in os.listdir(folder_path):\n",
        "                img = Image.open(os.path.join(folder_path, filename)).convert('L').resize((128, 128))\n",
        "                if img is not None:\n",
        "                    images.append(torch.tensor(np.array(img, dtype=np.float32)))\n",
        "            return torch.stack(images)\n",
        "\n",
        "    train_images = load_images_from_folder(train_path)\n",
        "    test_images = load_images_from_folder(test_path)\n",
        "    validate_images = load_images_from_folder(val_path)\n",
        "\n",
        "    # Print statements to understand the data\n",
        "    print(f\"Total train images: {len(train_images)}\")\n",
        "    print(f\"Shape of a single train image: {train_images[0].shape}\")\n",
        "    print(f\"Total test images: {len(test_images)}\")\n",
        "    print(f\"Shape of a single test image: {test_images[0].shape}\")\n",
        "    print(f\"Total validation images: {len(validate_images)}\")\n",
        "    print(f\"Shape of a single validation image: {validate_images[0].shape}\")\n",
        "\n",
        "return train_images, test_images, validate_images\n"
      ],
      "metadata": {
        "id": "4cFXg40HfDzG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "023dc604-29bb-4644-e7ad-f035020a0c8b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-c1c275b2c2c4>\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    return train_images, test_images, validate_images\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7hS9rkMYiCvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VinNRMXdfGcr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}